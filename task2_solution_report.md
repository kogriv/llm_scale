# Решение задачи Task2: Лаборатория биокибернетики

## Описание задачи
Бинарная классификация биологических объектов (человек/не человек) по 9 признакам (A-I).
- **Обучающая выборка**: 1000 объектов
- **Тестовая выборка**: 500 объектов
- **Баланс классов**: 71.2% класса 0, 28.8% класса 1
- **Целевая метрика**: ROC-AUC ≥ 0.88 для максимального балла

## Подход к решению

### 1. Предобработка данных
- Обработка категориального признака C (кодирование через LabelEncoder)
- Заполнение пропущенных значений медианой (75 пропусков в train, 43 в test)
- Учет дисбаланса классов через параметр `class_weight='balanced'`

### 2. Feature Engineering
Созданы дополнительные признаки:
- Попарные произведения важных признаков: A×D, A×I, A×G, A×H, B×E, B×F, D×G, D×H, E×F, E×I, G×H, G×I, H×I
- Квадраты ключевых признаков: A², D², G², H², I²
- Итоговый размер набора признаков: 27 (исходные 9 + 18 новых)

### 3. Тестирование моделей

#### Попытка 1: Sklearn модели
- Random Forest: ROC-AUC = 0.8509
- Gradient Boosting: ROC-AUC = 0.8600
- Extra Trees: ROC-AUC = 0.8519
- Ансамбль: ROC-AUC ≈ 0.86

#### Попытка 2: Расширенный Feature Engineering
- **AdaBoost: ROC-AUC = 0.8681**
- Gradient Boosting: ROC-AUC = 0.8600
- Extra Trees: ROC-AUC = 0.8519
- Random Forest: ROC-AUC = 0.8512

#### Попытка 3: LightGBM
Протестировано 8 различных конфигураций LightGBM:

| Конфигурация | n_estimators | learning_rate | max_depth | num_leaves | ROC-AUC |
|--------------|--------------|---------------|-----------|------------|---------|
| 1 | 2000 | 0.01 | 6 | 40 | 0.8488 |
| 2 | 2000 | 0.01 | 7 | 50 | 0.8542 |
| 3 | 1500 | 0.02 | 7 | 50 | 0.8558 |
| 4 | 1500 | 0.02 | 8 | 60 | 0.8580 |
| 5 | 1000 | 0.03 | 7 | 50 | 0.8543 |
| 6 | 1000 | 0.05 | 6 | 40 | 0.8515 |
| 7 | 1200 | 0.02 | 10 | 100 | 0.8569 |
| 8 | 1000 | 0.03 | 12 | 120 | 0.8556 |

Лучший результат LightGBM (0.8580) уступает AdaBoost (0.8681).

#### Попытка 4: CatBoost (финальное успешное решение)
- **CatBoost (10-fold CV): ROC-AUC = 0.8952** — целевая планка ≥0.88 преодолена
- Модель использует нативную обработку категориального признака `C` и автоматический баланс классов (`auto_class_weights="Balanced"`).
- Поиск по сетке из 12 комбинаций (`depth`, `learning_rate`, `l2_leaf_reg`, `bagging_temperature`) с остановкой после достижения порога качества.
- Лучшие гиперпараметры: `depth=5`, `learning_rate=0.05`, `l2_leaf_reg=3`, `bagging_temperature=0.6`.
- Модель дообучалась на полной обучающей выборке с количеством итераций, подобранным по отложенной выборке (`best_iteration=317`).
- Итоговые предсказания сохранены в `data/task2/task2_catboost_submission.csv`, а также в файле `data/task2/task2_catboost_submission_like_example.csv`, который повторяет формат `example.csv` и содержит бинарные метки 0/1.

## Лучший результат

**Модель**: CatBoostClassifier
**Скрипт**: `solve_task2_catboost.py`
**ROC-AUC на кросс-валидации (10-fold)**: **0.8952**

### Параметры лучшей модели
```python
CatBoostClassifier(
    depth=5,
    learning_rate=0.05,
    l2_leaf_reg=3,
    bagging_temperature=0.6,
    iterations=317,
    auto_class_weights="Balanced",
    loss_function="Logloss",
    eval_metric="AUC",
    random_seed=42
)
```

### Выводы
- CatBoost преодолел ключевой барьер ROC-AUC ≥ 0.88 благодаря более гибкой обработке категориальных признаков и регуляризации.
- Перебор гиперпараметров с ранней остановкой позволил найти устойчивую конфигурацию без переобучения.
- Формат итоговых предсказаний приведён в соответствие требованиям соревнования (две версии файла — с идентификаторами и в формате примера).
